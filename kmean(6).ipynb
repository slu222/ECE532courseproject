{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import collections\n",
    "random.seed(1117)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K is 6\n"
     ]
    }
   ],
   "source": [
    "# If set K to 2, then the original 6 labels will be divided into two labels: static state and active state\n",
    "\n",
    "K = 6\n",
    "print('K is {}'.format(K))\n",
    "TRAIN_DIR = 'UCI HAR Dataset/train'\n",
    "TEST_DIR = 'UCI HAR Dataset/test'\n",
    "\n",
    "\n",
    "def read_a_file(file):\n",
    "    \"\"\"\n",
    "    read_a_file: Read the data file, Each row is corresponding to one subject's motion. . Return a numpy array\n",
    "    file: the file path\n",
    "    \n",
    "    \"\"\"\n",
    "    f = open(file, 'r', encoding='utf-8')\n",
    "    data = []\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        x = [float(v) for v in line]\n",
    "        data.append(x)\n",
    "    f.close()\n",
    "    data = np.array(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    read_dataset: Read X and y form 'UCI HAR Dataset/train' or 'UCI HAR Dataset/test' . The returned X and y are used\n",
    "    as training or testing data set.\n",
    "\n",
    "    data_dir: file address 'UCI HAR Dataset/train' or 'UCI HAR Dataset/test'\n",
    "     X (A n * f matrix,where n is the number of samples, f is the number of features),\n",
    "     y (A n*1 matrix where n is corresponding to the number of labels)\n",
    "    \"\"\"\n",
    "    print('Read data from {}'.format(data_dir))\n",
    "    kind = 'train' if 'train' in data_dir else 'test'\n",
    "\n",
    "    # X has 2 parts: for train, it comes form X_train.txt and Inertial Signals\n",
    "    \n",
    "    # Part 1. X_train.txt or X_test.txt\n",
    "    X1 = read_a_file(os.path.join(data_dir, 'X_{}.txt'.format(kind)))\n",
    "    print('The data shape of X_{}.txt is {} × {}'.format(kind, X1.shape[0], X1.shape[1]))\n",
    "\n",
    "   \n",
    "    # Part 2. Inertial Signals\n",
    "    # IS_dir = os.path.join(data_dir, 'Inertial Signals')\n",
    "    # X2 = []\n",
    "    # for file_name in os.listdir(IS_dir):\n",
    "    #     file_path = os.path.join(IS_dir, file_name)\n",
    "    #     tmp = read_a_file(file_path)\n",
    "    #     X2.append(tmp)\n",
    "    # X2 = np.concatenate(X2, axis=1)\n",
    "    # print('The data shape of Inertial Signals is {} × {}'.format(X2.shape[0], X2.shape[1]))\n",
    "\n",
    "    # X = np.concatenate([X1, X2], axis=1)\n",
    "    \n",
    "    X = X1\n",
    "\n",
    "    # Read the y data\n",
    "    y = read_a_file(os.path.join(data_dir, 'y_{}.txt'.format(kind)))\n",
    "    y = y.reshape(-1)\n",
    "    y = [int(v) for v in y]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"\n",
    "    euclidean_distance: Computing the euclidean distance between two given points\n",
    "    a: One point\n",
    "    b: Another point\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    d = len(a)\n",
    "    cur_sum = 0\n",
    "    for i in range(d):\n",
    "        cur_sum += (a[i] - b[i]) ** 2\n",
    "    return sqrt(cur_sum)\n",
    "\n",
    "\n",
    "def center_point(points):\n",
    "    \"\"\"\n",
    "    center_point: Computing the center point of data points. Each dimension of the center point is\n",
    "    the mean of the points of the same dimension.\n",
    "    points: a list of points\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    d = len(points[0])\n",
    "\n",
    "    center = []\n",
    "\n",
    "    for i in range(d):\n",
    "        cur_sum = 0  # dimension sum\n",
    "        for p in points:\n",
    "            cur_sum += p[i]\n",
    "\n",
    "        # average of each dimension\n",
    "        center.append(cur_sum / float(n))\n",
    "\n",
    "    return center\n",
    "\n",
    "\n",
    "def update_centers(data, assignments):\n",
    "    \"\"\"\n",
    "    update_centers:According to each data point and their assignment, compute a center point for each kind of assignment\n",
    "    It returns to a list containing k centers\n",
    "    data: All data points\n",
    "    assignments: The assignments for all points, e.g., data[i] has the assignment of assignments[i]\n",
    "   \n",
    "    \"\"\"\n",
    "    ass_2_points = {}\n",
    "    for assignment, point in zip(assignments, data):\n",
    "        if assignment not in ass_2_points:\n",
    "            ass_2_points[assignment] = [point]\n",
    "        else:\n",
    "            ass_2_points[assignment].append(point)\n",
    "\n",
    "    centers = []\n",
    "    for points in ass_2_points.values():\n",
    "        centers.append(center_point(points))\n",
    "\n",
    "    return centers\n",
    "\n",
    "\n",
    "def assign_points(data, centers):\n",
    "    \"\"\"\n",
    "    assign_points:The assignments of all points. centers contain several center points. \n",
    "    For each point in the data, find the closest center point and its index,\n",
    "    use this index as the assignment of this point.\n",
    "    data: All data points\n",
    "    centers: Center points\n",
    "    \n",
    "    \"\"\"\n",
    "    assignments = []\n",
    "    for point in data:\n",
    "        closest = float('inf')  # positive infinity\n",
    "        closest_index = 0\n",
    "        for i in range(len(centers)):\n",
    "            val = euclidean_distance(point, centers[i])\n",
    "            if val < closest:\n",
    "                closest = val\n",
    "                closest_index = i\n",
    "        assignments.append(closest_index)\n",
    "    return assignments\n",
    "\n",
    "\n",
    "def kmeans_plusplus(data, k):\n",
    "    \"\"\"\n",
    "    kmeans_plusplus: Choose k points in data as k center points using K-means++ algorithm.\n",
    "    It returns to a list of k center points\n",
    "    data: All data points\n",
    "    k: The number of center points\n",
    "\n",
    "    \"\"\"\n",
    "    centers = list()\n",
    "    centers.append(random.choice(data))     # Choose the first center point\n",
    "    # find left k-1 center points\n",
    "    for i in range(1, k):\n",
    "        d = [min([euclidean_distance(x, c) for c in centers]) for x in data]\n",
    "        # use Roulette method to choose next center point\n",
    "        d = [p/sum(d) for p in d]\n",
    "        s = 0\n",
    "        for j in range(len(d)):\n",
    "            d[j] += s\n",
    "            s += d[j]\n",
    "        r = random.random()\n",
    "        for j, p in enumerate(d):\n",
    "            if r < p:\n",
    "                centers.append(data[j])\n",
    "                break\n",
    "    return centers\n",
    "\n",
    "\n",
    "def compare_two_assignments(a1, a2):\n",
    "    \"\"\"\n",
    "    compare_two_assignments: numbers of different values. \n",
    "    :param a1: One assignment\n",
    "    :param a2: Another assignment\n",
    "    \n",
    "    \"\"\"\n",
    "    diff = 0\n",
    "    for i, j in zip(a1, a2):\n",
    "        if i != j:\n",
    "            diff += 1\n",
    "    return diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from UCI HAR Dataset/train\n",
      "The data shape of X_train.txt is 7352 × 561\n",
      "The data shape of X is 7352 × 561\n",
      "The data shape of y is 7352 × 1\n",
      "\n",
      "Read data from UCI HAR Dataset/test\n",
      "The data shape of X_test.txt is 2947 × 561\n",
      "The data shape of X is 2947 × 561\n",
      "The data shape of y is 2947 × 1\n",
      "\n",
      "Start runing K-means...\n",
      "Begin 1 iteration...\n",
      "Begin 2 iteration...\n",
      "Begin 3 iteration...\n",
      "Begin 4 iteration...\n",
      "Begin 5 iteration...\n",
      "Begin 6 iteration...\n",
      "Begin 7 iteration...\n",
      "Begin 8 iteration...\n",
      "Begin 9 iteration...\n",
      "Begin 10 iteration...\n",
      "Begin 11 iteration...\n",
      "Begin 12 iteration...\n",
      "Begin 13 iteration...\n",
      "Begin 14 iteration...\n",
      "Begin 15 iteration...\n",
      "Begin 16 iteration...\n",
      "Begin 17 iteration...\n",
      "Begin 18 iteration...\n",
      "Begin 19 iteration...\n",
      "Begin 20 iteration...\n",
      "Begin 21 iteration...\n",
      "Begin 22 iteration...\n",
      "Begin 23 iteration...\n",
      "K-means done!\n",
      "4\n",
      "ass = 0, size = 1939, label = 5\n",
      "ass = 1, size = 852, label = 5\n",
      "ass = 2, size = 1288, label = 6\n",
      "ass = 3, size = 3273, label = 1\n",
      "{0: 5, 1: 5, 2: 6, 3: 1}\n",
      "When  K=6, The error rate for trainning dataset is 0.47782916213275295\n",
      "When K=6, the error rate for testing dataset is 0.6389548693586699\n"
     ]
    }
   ],
   "source": [
    "def run_k_means(X, k):\n",
    "    \"\"\"\n",
    "    run_k_means: Run the K-means algorithm. Partition the X into k clusters. It returns to the assignments of X.\n",
    "    X: All data points.\n",
    "    k: The final cluster number.\n",
    "    \n",
    "    \"\"\"\n",
    "    print('Start runing K-means...')\n",
    "    centers = kmeans_plusplus(X, k)\n",
    "    times = 10000\n",
    "    it = 1\n",
    "    assignments = assign_points(X, centers)\n",
    "    while it <= times:\n",
    "        print('Begin {} iteration...'.format(it))\n",
    "        centers = update_centers(X, assignments)\n",
    "        old_assignments = assignments[:]\n",
    "        assignments = assign_points(X, centers)\n",
    "        it += 1\n",
    "        cur_diff = compare_two_assignments(old_assignments, assignments)\n",
    "        if cur_diff == 0:\n",
    "            break\n",
    "    print('K-means done!')\n",
    "    return assignments, centers\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_X, train_y = read_dataset(TRAIN_DIR)\n",
    "    print()\n",
    "    test_X, test_y = read_dataset(TEST_DIR)\n",
    "    print()\n",
    "\n",
    "    if K == 2:\n",
    "        train_y = [0 if v in [1, 2, 3] else 1 for v in train_y]\n",
    "        test_y = [0 if v in [1, 2, 3] else 1 for v in test_y]\n",
    "\n",
    "    assignments, centers = run_k_means(train_X, K)\n",
    "\n",
    "    print(len(centers))\n",
    "   # print(assignments[:1000])\n",
    "\n",
    "    # The points of the same assignment is a class of points. Use the majority of true labels of each class as the\n",
    "    # label of this class. In the test phase, for each test point, computing the distance between it and the centers\n",
    "    # points, and choose the index of the closest center point as the class of this test point. Then using the label of\n",
    "    # this class as the predicted label of this test point.\n",
    "\n",
    "    # ass_2_label_lists is the list of true labels for points with the same assignment\n",
    "    ass_2_label_lists = {}\n",
    "    for i, ass in enumerate(assignments):\n",
    "        label = train_y[i]\n",
    "        if ass not in ass_2_label_lists:\n",
    "            ass_2_label_lists[ass] = [label]\n",
    "        else:\n",
    "            ass_2_label_lists[ass].append(label)\n",
    "\n",
    "    # ass_2_label is the label for each assignment, by counting the most frequent labels in the label lists\n",
    "    # of the assignment\n",
    "    ass_2_label = {}\n",
    "    for ass in ass_2_label_lists:\n",
    "        ct = collections.Counter(ass_2_label_lists[ass])\n",
    "        label = ct.most_common(1)[0][0]\n",
    "        ass_2_label[ass] = label\n",
    "\n",
    "        print('ass = {}, size = {}, label = {}'.format(ass, len(ass_2_label_lists[ass]), label))\n",
    "\n",
    "    print(ass_2_label)\n",
    "\n",
    "    # Test on train data\n",
    "    accuracy = 0\n",
    "    for i, x in enumerate(train_X):\n",
    "        # compute the assignment for this x\n",
    "        predicted_label = ass_2_label[assignments[i]]\n",
    "        if predicted_label == train_y[i]:\n",
    "            accuracy += 1\n",
    "    accuracy /= len(train_y)\n",
    "    print('When  K={}, The error rate for trainning dataset is {}'.format(K, 1-accuracy))\n",
    "    \n",
    "     # Test on test data\n",
    "    accuracy = 0\n",
    "    for i, x in enumerate(test_X):\n",
    "        # compute the assignment for this x\n",
    "        closest = float('inf')\n",
    "        assignment = 0\n",
    "        for i in range(len(centers)):\n",
    "            val = euclidean_distance(x, centers[i])\n",
    "            if val < closest:\n",
    "                closest = val\n",
    "                assignment = i\n",
    "        predicted_label = ass_2_label[assignment]\n",
    "        if predicted_label == test_y[i]:\n",
    "            accuracy += 1\n",
    "\n",
    "    accuracy /= len(test_y)\n",
    "    print('When K={}, the error rate for testing dataset is {}'.format(K, 1-accuracy))\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
