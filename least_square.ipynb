{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'UCI HAR Dataset/train'\n",
    "TEST_DIR = 'UCI HAR Dataset/test'\n",
    "\n",
    "\n",
    "def read_a_file(file):\n",
    "    \"\"\"\n",
    "    read_a_file: Read the data file, Each row is corresponding to one subject's motion. \n",
    "    file: the file path\n",
    "    \n",
    "    \"\"\"\n",
    "    f = open(file, 'r', encoding='utf-8')\n",
    "    data = []\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        x = [float(v) for v in line]\n",
    "        data.append(x)\n",
    "    f.close()\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    read_dataset: Read X and y form 'UCI HAR Dataset/train' or 'UCI HAR Dataset/test' . The returned X and y are used\n",
    "    as training or testing data set.\n",
    "\n",
    "    data_dir: file address 'UCI HAR Dataset/train' or 'UCI HAR Dataset/test'\n",
    "     X (A n * f matrix,where n is the number of samples, f is the number of features),\n",
    "     y (A n*1 matrix where n is corresponding to the number of labels)\n",
    "    \"\"\"\n",
    "    kind = 'train' if 'train' in data_dir else 'test'\n",
    "\n",
    "    # X has 2 parts: for train, it comes form X_train.txt, and Inertial Signals\n",
    "    # Part 1. X_train.txt or X_test.txt\n",
    "    X1 = read_a_file(os.path.join(data_dir, 'X_{}.txt'.format(kind)))\n",
    "    print('The data shape of X_{}.txt is {} × {}'.format(kind, X1.shape[0], X1.shape[1]))\n",
    "\n",
    "    \n",
    "    # Part 2. Inertial Signals\n",
    "    # IS_dir = os.path.join(data_dir, 'Inertial Signals')\n",
    "    # X2 = []\n",
    "    # for file_name in os.listdir(IS_dir):\n",
    "    #     file_path = os.path.join(IS_dir, file_name)\n",
    "    #     tmp = read_a_file(file_path)\n",
    "    #     X2.append(tmp)\n",
    "    # X2 = np.concatenate(X2, axis=1)\n",
    "    # print('The data shape of Inertial Signals is {} × {}'.format(X2.shape[0], X2.shape[1]))\n",
    "\n",
    "    # X = np.concatenate([X1, X2], axis=1)\n",
    "    \n",
    "    X = X1\n",
    "  \n",
    "    # Read the y data\n",
    "    y = read_a_file(os.path.join(data_dir, 'y_{}.txt'.format(kind)))\n",
    "    y = y.reshape(-1)\n",
    "    y = [int(v) for v in y]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data shape of X_train.txt is 7352 × 561\n",
      "\n",
      "The data shape of X_test.txt is 2947 × 561\n",
      "\n",
      "Using data from 0 to 2574 for test, other for training\n",
      "Error rate : 0.7703962703962703\n",
      "Using data from 2574 to 5148 for test, other for training\n",
      "Error rate : 0.45998445998445997\n",
      "Using data from 5148 to 7722 for test, other for training\n",
      "Error rate : 0.4627039627039627\n",
      "Using data from 7722 to 10296 for test, other for training\n",
      "Error rate : 0.45765345765345766\n"
     ]
    }
   ],
   "source": [
    "# The original 6 labels is divided into two new labels: static state and active state\n",
    "#labels 1, 2, 3 are corresponding to active state and it is converted as -1 in new label\n",
    "#labels 4, 5, 6 are corresponding to static state and it is converted as 1 in new label\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X1, y1 = read_dataset(TRAIN_DIR)\n",
    "    print()\n",
    "    X2, y2 = read_dataset(TEST_DIR)\n",
    "    print()\n",
    "    X = np.concatenate([X1, X2], axis=0)\n",
    "    y = y1 + y2\n",
    "    y= [-1 if v in [1, 2, 3] else 1 for v in y]\n",
    "    \n",
    "    # Divide all data into 4 sets, then using 2 sets as the training dataset\n",
    "    #Setting the other 2 sets as the testing dataset\n",
    "    sets = [[0, 2574], [2574, 2574*2], [2574*2, 2574*3], [2574*3, 2574*4]]\n",
    "    split_X = [X[g[0]:g[1], :] for g in sets]\n",
    "    split_y = [y[g[0]:g[1]] for g in sets]\n",
    "    for i, g in enumerate(sets):\n",
    "        \n",
    "        train_X = []\n",
    "        train_y = []\n",
    "        for j in range(4):\n",
    "            if j != i:\n",
    "                train_X.append(split_X[j])\n",
    "                train_y.extend(split_y[j])\n",
    "        train_X = np.concatenate(train_X, axis=0)\n",
    "        \n",
    "        test_X = split_X[i]\n",
    "        test_y = split_y[i]\n",
    "        \n",
    "        # w = (X^T X)^(-1)X^T y\n",
    "        weights = (train_X.T @ train_X) ** -1 @ train_X.T @ train_y\n",
    "        error_rate = (np.mean(np.sign(test_X @ weights) != test_y))\n",
    "        \n",
    "        print('Using data from {} to {} for test, other for training'.format(g[0], g[1]))\n",
    "        print('Error rate : '+str(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
